{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chemin_bd = r\"./bd_ignore/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tmdb = pd.read_csv(chemin_bd + 'tmdb_full.csv')  # Dataset des films\n",
    "df_names = pd.read_csv(chemin_bd + 'name.basics.tsv', sep='\\t')  # Dataset des acteurs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nettoyage des colonnes inutiles dans df_names\n",
    "df_names = df_names[['primaryName', 'knownForTitles']]  # Conserver uniquement les colonnes nécessaires\n",
    "\n",
    "# Exploser les titres associés (knownForTitles)\n",
    "df_names = df_names.assign(knownForTitles=df_names['knownForTitles'].str.split(','))\n",
    "df_names = df_names.explode('knownForTitles')  # Une ligne par titre associé\n",
    "\n",
    "# Nettoyer et convertir la colonne 'release_date' en datetime dans df_tmdb\n",
    "df_tmdb['release_date'] = pd.to_datetime(df_tmdb['release_date'], errors='coerce')\n",
    "df_tmdb['year'] = df_tmdb['release_date'].dt.year\n",
    "\n",
    "# Supprimer les lignes sans 'year' ou 'genres'\n",
    "df_tmdb = df_tmdb.dropna(subset=['year', 'genres'])\n",
    "\n",
    "# Filtrer les films des années 2000\n",
    "df_tmdb = df_tmdb[(df_tmdb['year'] >= 2000) & (df_tmdb['year'] <= 2024)]\n",
    "\n",
    "# Merge avec le dataset des acteurs sur 'imdb_id'\n",
    "df_tmdb['imdb_id'] = df_tmdb['imdb_id'].str.strip()  # Nettoyer d'éventuels espaces\n",
    "df_merged = pd.merge(df_tmdb, df_names, left_on='imdb_id', right_on='knownForTitles', how='left')\n",
    "\n",
    "# Ajouter les noms des acteurs groupés par film\n",
    "df_merged['actors'] = df_merged.groupby('imdb_id')['primaryName'].transform(lambda x: ', '.join(x.dropna()))\n",
    "df_merged = df_merged.drop_duplicates(subset=['imdb_id'])  # Supprimer les doublons\n",
    "\n",
    "# Sélection des colonnes pertinentes pour le modèle\n",
    "features = ['popularity', 'vote_average', 'vote_count', 'budget', 'revenue', 'runtime']\n",
    "df_filtered = df_merged[features + ['genres', 'actors', 'title']].fillna(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encodage des genres\n",
    "df_encoded = pd.concat(\n",
    "    [df_filtered[features], pd.get_dummies(df_filtered['genres'], prefix='genre')],\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Normalisation des données\n",
    "scaler = MinMaxScaler()\n",
    "X = scaler.fit_transform(df_encoded)\n",
    "\n",
    "# Modèle Nearest Neighbors\n",
    "k = 11 # Meilleure valeur de K = 6 d'aprés fig\n",
    "\n",
    "model = NearestNeighbors(n_neighbors=k, metric='euclidean')\n",
    "model.fit(X)\n",
    "\n",
    "# Fonction pour rechercher des films similaires\n",
    "def films_similaires(film_index):\n",
    "    distances, indices = model.kneighbors([X[film_index]])\n",
    "    print(\"Films similaires :\")\n",
    "    for i, index in enumerate(indices[0]):\n",
    "        film = df_filtered.iloc[index]\n",
    "        print(f\"{i + 1}: {film['title']} (distance: {distances[0][i]:.2f})\")\n",
    "        print(f\"   Acteurs: {film['actors']}\")\n",
    "\n",
    "# Exemple d'utilisation\n",
    "film_index = 0  # Index du film pour lequel vous voulez des recommandations\n",
    "films_similaires(film_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Titres disponibles dans la colonne 'title':\")\n",
    "print(df_filtered['title'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Réinitialiser les indices de df_filtered avant de normaliser les données\n",
    "df_filtered = df_filtered.reset_index(drop=True)\n",
    "\n",
    "# Normalisation des données\n",
    "scaler = MinMaxScaler()\n",
    "X = scaler.fit_transform(df_encoded)  # X doit être basé sur df_filtered encodé\n",
    "#\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_all_movie_distances(champion_movies):\n",
    "    # Préparation des données pour la PCA\n",
    "    pca = PCA(n_components=2)\n",
    "    X_pca = pca.fit_transform(X)  # X est votre matrice de données normalisées\n",
    "\n",
    "    # DataFrame pour les films\n",
    "    pca_df = pd.DataFrame(data=X_pca, columns=['PC1', 'PC2'])\n",
    "    pca_df['Title'] = df_filtered['title'].values  # Ajout des titres\n",
    "    pca_df['Type'] = 'Movie'\n",
    "\n",
    "    # Création du graphique\n",
    "    fig = go.Figure()\n",
    "\n",
    "    # Ajout des points pour tous les films\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=pca_df['PC1'],\n",
    "        y=pca_df['PC2'],\n",
    "        mode='markers',\n",
    "        marker=dict(color='lightgray', size=8, opacity=0.5),\n",
    "        name='Movies',\n",
    "        hovertext=pca_df['Title'],\n",
    "        hoverinfo='text'\n",
    "    ))\n",
    "\n",
    "    # Couleurs pour distinguer les films sélectionnés\n",
    "    colors = px.colors.qualitative.Set1\n",
    "\n",
    "    # Vérification des titres valides\n",
    "    for i, movie_title in enumerate(champion_movies):\n",
    "        if movie_title not in df_filtered['title'].values:\n",
    "            print(f\"Titre non trouvé dans le dataset : {movie_title}\")\n",
    "            continue  # Passer au titre suivant\n",
    "\n",
    "        # Récupération des caractéristiques du film\n",
    "        movie_index = df_filtered[df_filtered['title'] == movie_title].index[0]\n",
    "        movie_encoded = X[movie_index]  # Index aligné avec df_filtered après reset_index()\n",
    "\n",
    "        # Transformation PCA\n",
    "        movie_pca = pca.transform([movie_encoded])\n",
    "\n",
    "        # Ajout du film sélectionné\n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=[movie_pca[0, 0]],\n",
    "            y=[movie_pca[0, 1]],\n",
    "            mode='markers+text',\n",
    "            marker=dict(color=colors[i % len(colors)], size=15, symbol='star'),\n",
    "            name=movie_title,\n",
    "            text=[movie_title],\n",
    "            textposition=\"top center\",\n",
    "            hoverinfo='text'\n",
    "        ))\n",
    "\n",
    "        # Récupération des plus proches voisins\n",
    "        distances, indices = model.kneighbors([movie_encoded])\n",
    "        similar_movies = df_filtered.iloc[indices[0][1:4]]  # Les 3 plus proches voisins\n",
    "\n",
    "        # Trouver les coordonnées PCA des films similaires\n",
    "        similar_pca = pca.transform(X[indices[0][1:4]])\n",
    "\n",
    "        # Ajout des films similaires avec des lignes les reliant au film sélectionné\n",
    "        for j in range(len(similar_pca)):\n",
    "            # Ligne reliant le film sélectionné à son similaire\n",
    "            fig.add_trace(go.Scatter(\n",
    "                x=[movie_pca[0, 0], similar_pca[j, 0]],\n",
    "                y=[movie_pca[0, 1], similar_pca[j, 1]],\n",
    "                mode='lines',\n",
    "                line=dict(color=colors[i % len(colors)], width=1, dash='dot'),\n",
    "                showlegend=False,\n",
    "                hoverinfo='none'\n",
    "            ))\n",
    "\n",
    "            # Point du film similaire\n",
    "            fig.add_trace(go.Scatter(\n",
    "                x=[similar_pca[j, 0]],\n",
    "                y=[similar_pca[j, 1]],\n",
    "                mode='markers+text',\n",
    "                marker=dict(color=colors[i % len(colors)], size=10),\n",
    "                name=f'Similar to {movie_title}',\n",
    "                text=[similar_movies.iloc[j]['title']],\n",
    "                textposition=\"top center\",\n",
    "                showlegend=False,\n",
    "                hovertext=[f\"Similar to {movie_title}: {similar_movies.iloc[j]['title']}\"],\n",
    "                hoverinfo='text'\n",
    "            ))\n",
    "\n",
    "    # Mise à jour du layout\n",
    "    fig.update_layout(\n",
    "        title='PCA: Selected Movies and Their Similar Movies',\n",
    "        xaxis_title=f'PC1 (Variance: {pca.explained_variance_ratio_[0]:.2%})',\n",
    "        yaxis_title=f'PC2 (Variance: {pca.explained_variance_ratio_[1]:.2%})',\n",
    "        hovermode='closest',\n",
    "        width=800,\n",
    "        height=800\n",
    "    )\n",
    "\n",
    "    # Afficher le graphique\n",
    "    fig.show()\n",
    "\n",
    "    # Afficher l'information sur la variance expliquée totale\n",
    "    total_var = pca.explained_variance_ratio_.sum()\n",
    "    print(f\"\\nTotal variance explained by these 2 components: {total_var:.2%}\")\n",
    "\n",
    "# Utilisation de la fonction\n",
    "selected_movies = ['Inception', 'Avatar', 'The Dark Knight']  # Exemple de films sélectionnés\n",
    "visualize_all_movie_distances(selected_movies)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import numpy as np\n",
    "\n",
    "# Fonction pour évaluer différentes valeurs de k\n",
    "def evaluate_k(X_encoded, k_range):\n",
    "    avg_distances = []\n",
    "\n",
    "    for k in k_range:\n",
    "        # Modèle Nearest Neighbors\n",
    "        model = NearestNeighbors(n_neighbors=k, algorithm='auto', metric='euclidean')\n",
    "        model.fit(X_encoded)\n",
    "\n",
    "        # Moyenne des distances aux k plus proches voisins\n",
    "        distances, _ = model.kneighbors(X_encoded)\n",
    "        avg_distance = distances[:, -1].mean()  # Moyenne de la dernière colonne (k-ème distance)\n",
    "        avg_distances.append(avg_distance)\n",
    "\n",
    "    return avg_distances\n",
    "\n",
    "# Définition de la plage de k à tester\n",
    "k_range = range(1, 21)  # Test des valeurs de k de 1 à 20\n",
    "\n",
    "# Évaluation des différentes valeurs de k\n",
    "X_sample = X[:1000]  # Limiter à un sous-échantillon pour accélérer\n",
    "avg_distances = evaluate_k(X_sample, k_range)\n",
    "\n",
    "# Création d'une visualisation pour aider à choisir k\n",
    "plt.figure(figsize=(6, 5))\n",
    "plt.plot(k_range, avg_distances, 'bo-')\n",
    "plt.xlabel('Nombre de voisins (k)')\n",
    "plt.ylabel('Distance moyenne aux voisins')\n",
    "plt.title('Distance moyenne en fonction de k')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "def evaluate_k_with_silhouette(X_encoded, k_range):\n",
    "    avg_distances = []\n",
    "    silhouette_scores = []\n",
    "\n",
    "    for k in k_range:\n",
    "        # Modèle Nearest Neighbors\n",
    "        model = NearestNeighbors(n_neighbors=k, algorithm='auto', metric='euclidean')\n",
    "        model.fit(X_encoded)\n",
    "\n",
    "        # Moyenne des distances aux k plus proches voisins\n",
    "        distances, _ = model.kneighbors(X_encoded)\n",
    "        avg_distance = distances[:, -1].mean()\n",
    "        avg_distances.append(avg_distance)\n",
    "\n",
    "        # Clustering avec K-Means pour silhouette_score\n",
    "        if k > 1:\n",
    "            kmeans = KMeans(n_clusters=k, random_state=42).fit(X_encoded)\n",
    "            labels = kmeans.labels_\n",
    "            silhouette = silhouette_score(X_encoded, labels)\n",
    "            silhouette_scores.append(silhouette)\n",
    "        else:\n",
    "            silhouette_scores.append(0)\n",
    "\n",
    "    return avg_distances, silhouette_scores\n",
    "\n",
    "# Définition de la plage de k à tester\n",
    "k_range = range(2, 21)  # K-Means nécessite au moins k=2\n",
    "\n",
    "# Évaluation des distances moyennes et du score de silhouette\n",
    "avg_distances, silhouette_scores = evaluate_k_with_silhouette(X_sample, k_range)\n",
    "\n",
    "# Création d'une visualisation pour aider à choisir k\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# Premier graphique : Distance moyenne aux voisins\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(k_range, avg_distances, 'bo-')\n",
    "plt.xlabel('Nombre de voisins (k)')\n",
    "plt.ylabel('Distance moyenne aux voisins')\n",
    "plt.title('Distance moyenne en fonction de k')\n",
    "plt.grid(True)\n",
    "\n",
    "# Second graphique : Score de silhouette\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(k_range, silhouette_scores, 'ro-')\n",
    "plt.xlabel('Nombre de clusters (k)')\n",
    "plt.ylabel('Score de silhouette')\n",
    "plt.title('Score de silhouette en fonction de k')\n",
    "plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
